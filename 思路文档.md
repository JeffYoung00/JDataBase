##### 工作总结

lock table并发

cache manager: 冷热分离的lru

recovery manager: redo+undo+动态断点

各种隔离级别的实现, 给出的隔离级别不能解决幻读

constant泛型

b tree index/hash index

语义检查

scan/materialize/plan/planner

plan计算, hyperloglog等统计数据

planner

##### idea

cache预热

表锁, 幻读

支持null值

- mysql的记录头=变长字段列表, null值bit列表

- insert/delete format

如果有view, 递归一轮

##### 文件格式

命名

- log.log

- tableCatalog.tbl

- fieldCatalog.tbl

- indexCatalog.tbl

- xxx.tbl

- xxx.tmp.tbl

- xxx.hidx

- xxx.bidx

log block 格式

- boundary-- space-- [len content]
- 倒着写, 新log在前

log格式:

- checkpoint: type+-1+int数组

- commit/rollback/start: type+transaction id

- update: type+transaction id+blockid + offset + old value+new value

data/tempdata block格式: 定长/不跨块/同表

- [usedFlag/nextPointer data] ... firstRecordPointer

B tree index block格式, rootblock记录在indexinfo里面

- [nextEmptyPointer/nextRecordPointer blockNo. slotNo. key] ... [header] , rootblock记录在indexinfo里面

- directory header: isLeaf count firstEmptyPointer firstRecordPointer(有序) finalBlockNo

- leaf header: isLeaf count firstEmptyPointer firstRecordPointer(有序) previousBlockNo. nextBlockNo.

- 初始,fep=0,frp=-1; full,fep=order,frp=...

hash index block data: [usedFlag/nextPointer blockNo. slotNo.  hash]... count firstEmptyPointer localDepth

- 这里不记录key, 直接比较hash

hash index block bucket: []

- 每个块的数据量是固定的4096/16=256, 最大一共24bit用于hash

- 每个桶的数据量是固定的4096/4=1024, depth<10时bucket还是在一个page中分裂

- 用末尾的hash更好,这样xxx0,xxx1分裂为xxx00,xxx01,xxx10,xxx11,直接往下复制一份

---

是否需要count+delete adjustment?

- 因为要有序, 最好还是加上吧

- insert快速找到结尾

- 不加, insert找到empty也还是要往下找, 方便判断是否满

##### 定期更新

recovery.doRecover

recovery.dynamic checkpoint

statistics update

temp table delete

##### 初始化总结

file manager: 需要database dir被创建

file manager会用rwSyn模式打开所有文件, 没有会创建

log manager: 需要log.log文件

index manager: 需要index catalog文件

table manager: 需要table catalog, field catalog文件

##### 模块划分

模块

- 前端和词法分析, jdbc, parse

- 文件存储, file

- 内存管理, cache

- 事务和恢复机制, log, recovery, transaction

- 索引算法, index

- 查询前置, predicate, metadata, record

- 查询树, scan, plan, planner, materialize

##### 语法

select (没有as) from ... where ... (只能and连接, 字段只能=常量/字段)

没有group by/order by/*/null/join/union

insert 不能和 select 联动

update只能set赋值一次

##### 异常

语法异常(syntax)

文件系统异常(bad reading)

网络异常

资源争夺/死锁(no free cache/no available lock)

内部错误

##### jdbc

drivermanager.connect(url) ->call 自己的driver.connect()

- DriverManager.registerDriver()注册driver到registered drivers中

- 遍历registered drivers, 根据url找对应driver建立连接

使用jdbc

- Class.forName() 加载driver类, 可以在自己模块下/其他依赖模块/依赖库中

- Connection conn=DriverManager.getConnection(url,uesr,password)

实现Driver接口

- acceptsURL()判断url

- connect()调用, 创建连接, 并进行username, password的判断

- 加载类后直接执行DriverManager.registerDriver(new MyDriver(...));

##### parse

实现

- java.stream tokenizer

- 递归LL(1)语法

简单的语法

- select不能连用, *暂时没有group*

- insert只能插入一条数据(fields)

- update只能修改一个字段

- create index只能在一个字段上

- 谓语
  
  - filed/constant->expression->term->predicate
  
  - expression拓展, < >
  
  - term or term
  
  - expression > >=
  
  - insert + select
  
  - group by/sort

##### file

用文件操作进行管理, 每个文件看作是多个块

page类进行具体的字节操作

##### cache

transaction每次使用一个块, 就会先通知cachemanager换页(cachemanager.pin(blockid))

cache被transaction使用的时候不能被换出去, 替换时要找有没有空闲的

数据结构

- free queue, 用于初始化的queue, 数据库使用频率低下来后, 也可以让一部分空闲的cache回到free queue, 减小内存占用

- lrumap是linkedhashmap, 按顺序记录**所有的**blockid->cache, 最后面的就是least recently used, 进行替换

lru优化

1. 预热

2. young/old list, 防止大表污染
   
   1. 转换条件: 根据cache.date和cache.total pins和cache manager.total pins

3. 每个用户最多10%的buffer

##### log

一直在用一个page读写log.log

log的粒度是每一次的修改

部分操作(写temp table, recover)不需要再log

log需要用于recovery, 需要优先保证写回

- 每次写log都刷新回文件系统, 太低效

- 每次等一个block写完再刷新, 不能保证recovery

- 记录last saved log number, 写log需要传入log number并比较

##### recovery

log类型: checkpoint, commit, rollback, start, setInt, setString

成功recover的前提

- recover操作的幂等性

- 修改语句可以反向操作

- 避免 没写log&&写回disk, 因为这可能写回了一部分内容需要redo -> 先写log再写回disk(flush cache)
  
  - 写了log&&没写回disk 的情况可以用log恢复

- **后面都假定, 每次log写回了**

---

正常shutdown->将buffer中的内容写入file

意外shutdown->启动时recover

- 未完成=没有commit/rollback->undo
  
  - 就算完成了全部update没有写最后commit/rollback也是未完成

- 已完成未flush写回->redo

- **recovery manager的目标: undo...和redo...**

- 不能每次等recover的时候再去看所有的log->checkpoint

---

log太大

- 静态断点: 只有一个checkpoint, 恢复时不需要管前面的内容

- 动态断点: 有checkpoint: [transaction], 恢复时需要找到第一个running transaction的start

- 前面的内容就可以直接删除了, 动态断点也可以checkpoint时往前找来删除

undo操作: 后往前, 找对应transaction, 执行反向操作

redo: 前往后, 找对应transaction, 执行正向操作

redo-only策略: 要保证没有提交的事务的disk不会写回, 这很危险, 因为正常flush就需要写回

*正常替换总是会flush disk/log*

undo-only策略: 意外shutdown比较多, recover/checkpoint快

- 前提: 所有commit/rollback的transaction都写回了disk和log, 这样就不需要redo
- 静态断点: 某个时间(如启动时)不再新建事务, 处理完所有的事务并flush to file(所有事务缓存一致), 然后重新开始, 记录
- 动态断点: 不新建事务, 记录running transaction(commit已经确保了一致性)

undo+redo策略: commit快

- 前提: 所有commit/rollback的事务写回了log

- 动态断点: 某个时间, 不再创建新事务, 只flush(确保之前commit事件的缓存一致)不等, 写下当前running所有事务的断点

###### thinking

修改的时候是log first, 但commit/rollback需要完成才log

undo-only是否可以动态断点?: 可以, 并且还有优势

undo-only为什么要commit后立即刷新?: a commit, 写log, crash, log中有commit而disk中没有, 需要redo

是否可以将log保存在事务中?: 不可以, log粒度小, 要保存的内容太多

原文的undo-redo没有说重复执行rollback, 如果a update, a rollback, 一部分update的内容写回, rollback内容没有被写回, crash

- rollback和uncompleted都要undo

- commit需要redo

##### transaction

实现acid

- atomic: 由transaction.recovery实现, 执行到一半的会被undo

- consistency: 客户自己的责任

- isolation: transaction.concurrency提供读写锁, transaction实现具体的隔离级别

- durability: 肯定是实现了的

管理自己的cache和lock, 并作为各种操作的基本实现者, 提供方法

串行化=和串行一样的效果的并发级别

隔离实现

1. lock

2. multi version(copy on write)

lock table: 每个blockId上有读写锁, 事务结束时释放

死锁检测

- 画图

- 超时检测

死锁处理

- wait die: T2有锁, T1更早, 可以等, T1更晚, 直接回滚

- wound die: T1更早, 回滚, T1更晚, kill T2

- 等待超时直接回滚

**申请x锁之前先申请s锁, 因为不知道是不是自己身上的s锁导致冲突**

###### 隔离级别

hold x lock=read uncommitted, 因为没有读锁, A写后未提交的数据B可以读, 不可以写->脏读

hold x lock, 提前release s lock=read committed

- 占有x锁对方无法读->解决脏读

- A读后B写, A再读需要等到B结束, 这时可能数据被修改(update block影响了数据库)->不可重复读

hold x/s lock=read repeatable

- 占有s锁, 写方也无法修改->解决不可重复读

- append block操作影响了数据库->幻读

hold x/s/eof lock=serializable

###### 实现

![](file://C:\Users\21029\AppData\Roaming\marktext\images\2023-06-29-16-43-05-image.png?msec=1692001434139?msec=1695706124575)

**写入时都要加上x锁, 并且直到结束才释放**

read uncommitted: x锁

read committed: s(eof), s

- 提前释放, 包括eof

- 根据transaction的pinned caches.size和占有的锁决定提前释放, 不能放在用的表

read repeated: s(eof), s

###### thinking

每个tableScan都会申请slock(eof block), 但是insert不一定会申请xlock(eof block), 不能解决幻读

但append加上xlock(eof)肯定还是需要的, 只是slock(eof)只能防止脏读

如何解决幻读? tableScan申请表s锁, insert加表x锁

*先不解决幻读吧...*

##### record

实现简单的存储模式: 定长/不换块/同表

field, 类型, 长度, 名字

schema=表/record, map filedName -> field

layout=表/record的存储结构, map fieldName -> offset, recordSize

table scan(filename, Layout), 管理一个table

- record page, 辅助计算offset

chunk scan, 多个record page辅助

##### metadata

tablemanager: 增删, table的基本信息 layout

indexmanager: 增删, index的基本信息

修改table/index==在修改对应的catalog表

statisticsmanager: table的统计信息

- field的最小值/最大值/null/**distinct**

- **block/record**

更新(**有误差可以接受**)

- 少量数据估算全局

- hyper log log全计算

保存

- 保存在内存中, 每次开启计算, 定时计算

- 保存在统计的catalog中, 使用read uncommitted级别

##### predicate

constant/field->expression->term->predicate

term

- field 比 常量

- field 比 field, <mark>predicate中可能有多个Ta.field... = Tb.field</mark>

- 常量 比 常量

简单的语法

- expression只能是field/常量

- term只能=比较

- predicate只能and连接

###### thinking

recordpage.get/setValue创建constant

需要使用constant的equals和compareTo方法

- 用Object没有compareTo方法

- 不能用Comparable<?>代替, Integer.compareTo(Integer)而非Integer.compareTo(Comparable)

- 只能用泛型包装类

- 我想用的是constant<?>.compareTo(constant<?>), 因为两边都不知道具体类型, 无法通过constant实现comparable<constant<T>>, 编译时期就会显示?无法转到另一个?, 可以选择实现comparable<constant<?>>

- <mark>objects.compare?</mark>

##### scan和materialize

table scan根据metadata, 知道具体的存储格式, 直接getValue代替getInt/getString

scan可以理解为一个表的iterator(select), 一级一级的scan组成了流水线, 实际上只进行了一次tablescan

update语句会使用到table scan和select scan进行update, 所以这两者实现了update scan接口

---

全部scan

- 一次性操作, material(用于multi 右), mergeSort, hashBucket

- 底层scan, tableScan, indexScan+tableScan, chunkScan

- 上层scan, select, project, product, multiProduct mergeJoin, hashJoin, group+func

- index: indexJoin, indexSelect

- product(scan,chunk scan)->multi product->hash join
  
  - hash join在大部分情况下可以直接用product, 但有的桶太大没办法, 需要multi product

temporary table: 不记录log, 自动被删除

join

- indexjoin: 每个key回表一次, 找index只需要3 block

- merge join: 先sort然后两边遍历, 如果左表不重复, 只需要遍历一次, 如果左表重复, 右表需要回退(保存位置), 一般左表是主键表, 右表foreign key on left

- hash join: 先用hash值将两个表划分为多个小表, 具有相同hash值的两个表直接multi buffer scan
  
  - 动态划分, expected size=2xbuffer size

##### plan

每个plan来打开关闭对应的scan

每个plan动态组成schema

每个plan有固定cost和遍历cost, 固定cost即使用一次性操作的cost

前置

- statistics信息, distinct value

- index信息, height

---

R()V(), 假定R2更小

- select: 修改R大小
  
  - A=c, 修改R大小, V随之改变
  
  - A=B和其他意义不明的情况(如函数), 暂定为Uncountable_Factor

- product: R1xR2, V不变

- join: R1xR2/max(V1,V2), V(R1)=V(R1)xV1/V2 V(R2)不变

B()

- project/select不变, product不会使用

- index select: R+height

- multi product

- index join

- merge join

- hash join

buffer

- multi, 需要右表的1/n+1

- hash, 需要右表的根号+1, 最后2

- merge, 需要两个表的根号+1, 最后2

注意

- scan !!scan.before first(开局调用, 而非被动调用), !!scan.close

- scan !!tempTable.empty

- plan !!plan.open(打开, 之前只是计算)

- plan !!layout schema的重复, 尽量open再创建layout

##### planner

我的优化思路

- 所有的table创建table planner, 决定select/project

- 找最大连通量, 从最少records的节点开始join, product放到最后

- 根据当前cache使用情况, 拿到cache使用上限x

- index join/hash join/merge join计算cost比较

multi带来的麻烦

- 左右

- materialize之后的左右

- 最后的multi product遍历多次cost会更高

multi

- 总选择materialize后更小的作为右表(不然就有materialize左, materialize右, 不materialize三种选择, 并再选择左右表, 当然不会左右都materialize, 那样肯定不如hash; 这样是合理的, 因为plan时能成功装入并不代表执行最后执行时能成功装入, 减小内存消耗总是合理的)
- 但是可能多次遍历左表, material也能优化不少
- product左表之后如果后面没有select/project, material意义也不大

material/select之后的blocksize是无法计算的, 所以具体的buffer分配要交给具体执行的时候, planner只能根据当时的内存情况计算

启发式+join顺序

使用index select还是table select

使用product+select, product+materialize+select, hash+select, index, 还是merge

- product: 可能有小固定cost, 大遍历cost

- hash: 固定cost, 小遍历cost

- merge: 固定cost, 小遍历cost

- index: 未知遍历cost

- hash/merge留其一

- if index.遍历cost<hash.遍历cost then 选择index

- if index.遍历cost>hash.遍历cost+固定cost then 淘汰index

- if product.遍历+固定>hash.遍历+固定 then 淘汰product

- 最后可能留一两个

困难

1. 不一定所有的谓词都是单表+join, 最后product, 可能还有constant和多余的join谓词, 函数field谓词

2. 最后如何project

3. hash/merge/materialize有cost, 这是全局的

4. multi左表会多次遍历

##### jdbc执行流程

启动数据库, 放进Driver中

DriverManager.getConnection根据连接的url, 返回对应数据库的连接

创建连接直接打开new transaction, 每次commit/rollback换transaction, close关transaction

statement.execute(), 保留updateCount或resultSet, 查询执行了部分,等最后遍历结果

statement.getResultSet(), 执行plan

statement.execute/close(), 关闭上一次的result set

result set.next(), 遍历结果

result set.close(), 关闭scan

scan.close(), 关闭record page

record page.close(), unpin

前端

- begin transaction/commit/rollback

- 直接一句然后commit

异常

- statement.execute, 在语法/语义分析阶段的异常, 执行过程的异常

- resultSet.next, 执行过程的异常(锁, cache, 服务器内部异常)

- 异常之后rollback

##### 读写执行流程

schema->layout->record page->table scan->result set

不应该向外抛出异常

result set.getObject(i)

->table scan.getValue(fieldName)

->record page.getValue(slotNumber, fieldName)

->transaction.getInt/String(blockId, offset)

->对应page.getInt/String(offset)

layout.hasField->scan.hasField->product scan

##### 理解.index

hash index, 最好unique再使用

要么insert遍历, 要么delete/split整理

数组对比treenode

- treenode在不平衡的时候占空间更少

- treenode不方便存储

index entry为什么不要slot number?->减小存储压力, io才是重点?->如果只存储block numebr, 那么被delete之后要怎么通知index

hash index entry

- v hash

- key

- v block number

- slot number

btree index entry

- hash

- v key

- v block number

- slot number

不实现primary key, 创建索引==insert(所有key)

BTreePage vs Block

- block的数据有RecordId, 而BTreePage中的数据为了有序需要频繁移动

BTree的重复, 直接找到节点之后利用底层的有序固定往后遍历, 就不需要专门处理重复

##### todo

不写log

同步问题

- 修改table, 修改table statistics

- 修改index, 修改index高度

- 修改table, 修改index

语义检查的term两边
